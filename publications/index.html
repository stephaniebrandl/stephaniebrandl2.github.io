<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Stephanie Brandl</title> <meta name="author" content="Stephanie Brandl"/> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://stephaniebrandl.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Stephanie </span>Brandl</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <p><a href="">*</a> denotes equal contribution</p> <div class="publications"> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Trust</abbr></div> <div id="brandl-etal-2024-interplay" class="col-sm-8"> <div class="title">On the Interplay between Fairness and Explainability</div> <div class="author"> <em>Brandl S.</em>, Bugliarello E., and Chalkidis I.</div> <div class="periodical"> <em>In Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.trustnlp-1.10.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1717886845118197922?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="/assets/pdf/poster_trust24.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In order to build reliable and trustworthy NLP applications, models need to be both fair across different demographics and explainable. Usually these two objectives, fairness and explainability, are optimized and/or examined independently of each other. Instead, we argue that forthcoming, trustworthy NLP systems should consider both. In this work, we perform a first study to understand how they influence each other: do fair(er) models rely on more plausible rationales? and vice versa. To this end, we conduct experiments on two English multi-class text classification datasets, BIOS and ECtHR, that provide information on gender and nationality, respectively, as well as human-annotated rationales. We fine-tune pre-trained language models with several methods for (i) bias mitigation, which aims to improve fairness; (ii) rationale extraction, which aims to produce plausible explanations. We find that bias mitigation algorithms do not always lead to fairer models. Moreover, we discover that empirical fairness and explainability are orthogonal.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div> <div id="chalkidis-brandl-2024-llama" class="col-sm-8"> <div class="title">Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs</div> <div class="author"> Chalkidis I.*, and <em>Brandl S.*</em> </div> <div class="periodical"> Jun 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.naacl-short.40.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1772213802391490804?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/coastalcph/eu-politics-llms" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_eullama.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model’s political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUandI questionnaire. Llama Chat shows considerable knowledge of national parties’ positions and is capable of reasoning in context. The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LREC-COLING</abbr></div> <div id="brandl-etal-2024-evaluating" class="col-sm-8"> <div class="title">Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations</div> <div class="author"> <em>Brandl S.</em>, Eberle O., Ribeiro T., Søgaard A., and Hollenstein N.</div> <div class="periodical"> May 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.lrec-main.580.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1763491432956858481" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/rationales-eyetracking-xai" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_lrec24.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking QA, with attention and explainability-based importance scores for 4 different multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.</p> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div> <div id="cabello2023evaluating" class="col-sm-8"> <div class="title">Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models</div> <div class="author"> Cabello L., Bugliarello E., <em>Brandl S.</em>, and Elliott D.</div> <div class="periodical"> <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em> Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.emnlp-main.525.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/coastalcph/gender-neutral-vl" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_multimodal.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Pretrained machine learning models are known to perpetuate and even amplify existing biases in data, which can result in unfair outcomes that ultimately impact user experience. Therefore, it is crucial to understand the mechanisms behind those prejudicial biases to ensure that model performance does not result in discriminatory behaviour toward certain groups or populations. In this work, we define gender bias as our case study. We quantify bias amplification in pretraining and after fine-tuning on three families of vision-and-language models. We investigate the connection, if any, between the two learning stages, and evaluate how bias amplification reflects on model performance. Overall, we find that bias amplification in pretraining and after fine-tuning are independent. We then examine the effect of continued pretraining on gender-neutral data, finding that this reduces group disparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without significantly compromising task performance.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div> <div id="eberle2023nurse" class="col-sm-8"> <div class="title">Rather a Nurse than a Physician – Contrastive Explanations under Investigation</div> <div class="author"> Eberle O.*, Chalkidis I.*, Cabello L., and <em>Brandl S.</em> </div> <div class="periodical"> <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em> Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.emnlp-main.427.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1715001280370757846?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/coastalcph/humans-contrastive-xai" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_contrastive.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Contrastive explanations, where one decision is explained in contrast to another, are supposed to be closer to how humans explain a decision than non-contrastive explanations, where the decision is not necessarily referenced to an alternative. This claim has never been empirically validated. We analyze four English text-classification datasets (SST2, DynaSent, BIOS and DBpedia-Animals). We fine-tune and extract explanations from three different models (RoBERTa, GTP-2, and T5), each in three different sizes and apply three post-hoc explainability methods (LRP, GradientxInput, GradNorm). We furthermore collect and release human rationale annotations for a subset of 100 samples from the BIOS dataset for contrastive and non-contrastive settings. A cross-comparison between model-based rationales and human annotations, both in contrastive and non-contrastive settings, yields a high agreement between the two settings for models as well as for humans. Moreover, model-based explanations computed in both settings align equally well with human rationales. Thus, we empirically find that humans do not necessarily explain in a contrastive manner.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arxiv</abbr></div> <div id="ribeiro2023webqamgaze" class="col-sm-8"> <div class="title">WebQAmGaze: A Multilingual Webcam Eye-Tracking-While-Reading Dataset</div> <div class="author"> Ribeiro T., <em>Brandl S.</em>, Søgaard A., and Hollenstein N.</div> <div class="periodical"> Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2303.17876.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>We create WebQAmGaze, a multilingual low-cost eye-tracking-while-reading dataset, designed to support the development of fair and transparent NLP models. WebQAmGaze includes webcam eye-tracking data from 332 participants naturally reading English, Spanish, and German texts. Each participant performs two reading tasks composed of five texts, a normal reading and an information-seeking task. After preprocessing the data, we find that fixations on relevant spans seem to indicate correctness when answering the comprehension questions. Additionally, we perform a comparative analysis of the data collected to high-quality eye-tracking data. The results show a moderate correlation between the features obtained with the webcam-ET compared to those of a commercial ET device. We believe this data can advance webcam-based reading studies and open a way to cheaper and more accessible data collection. WebQAmGaze is useful to learn about the cognitive processes behind question answering (QA) and to apply these insights to computational models of language understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TACL</abbr></div> <div id="brandl2022domain" class="col-sm-8"> <div class="title">Domain-Specific Word Embeddings with Structure Prediction</div> <div class="author"> Lassner D.*, <em>Brandl S.*</em>, Baillot A., and Nakajima S.</div> <div class="periodical"> <em>Transactions of the Association for Computational Linguistics</em> Mar 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00538/2075946/tacl_a_00538.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1580128968673734661?s=20&amp;t=dcHLxlBouKiUgVKE7FvlZw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/domain-word-embeddings" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_acl23.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Complementary to finding good general word embeddings, an important question for representation learning is to find dynamic word embeddings, for example, across time or domain. Current methods do not offer a way to use or predict information on structure between sub-corpora, time or domain and dynamic embeddings can only be compared after post-alignment. We propose novel word embedding methods that provide general word representations for the whole corpus, domain- specific representations for each sub-corpus, sub-corpus structure, and embedding alignment simultaneously. We present an empirical evaluation on New York Times articles and two English Wikipedia datasets with articles on science and philosophy. Our method, called Word2Vec with Structure Prediction (W2VPred), provides better performance than baselines in terms of the general analogy tests, domain-specific analogy tests, and multiple specific word embedding evaluations as well as structure prediction performance when no structure is given a priori. As a use case in the field of Digital Humanities we demonstrate how to raise novel research questions for high literature from the German Text Archive.</p> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AACL</abbr></div> <div id="brandl-hollenstein-2022-every" class="col-sm-8"> <div class="title">Every word counts: A multilingual analysis of individual human alignment with model attention</div> <div class="author"> <em>Brandl S.</em>, and Hollenstein N.</div> <div class="periodical"> <em>In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.aacl-short.10.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1574712904175259648?s=20&amp;t=rSziizmyafl5IxqjOgsOeA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/eyetracking-subgroups" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Human fixation patterns have been shown to correlate strongly with Transformer-based attention. Those correlation analyses are usually carried out without taking into account individual differences between participants and are mostly done on monolingual datasets making it difficult to generalise findings. In this paper, we analyse eye-tracking data from speakers of 13 different languages reading both in their native language (L1) and in English as language learners (L2). We find considerable differences between languages but also that individual reading behaviour such as skipping rate, total reading time and vocabulary knowledge (LexTALE) influence the alignment between humans and models to an extent that should be considered in future studies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CLASP</abbr></div> <div id="morger-etal-2022-cross" class="col-sm-8"> <div class="title">A Cross-lingual Comparison of Human and Model Relative Word Importance</div> <div class="author"> Morger F., <em>Brandl S.</em>, Beinborn L., and Hollenstein N.</div> <div class="periodical"> <em>In Proceedings of the 2022 CLASP Conference on (Dis)embodiment</em> Sep 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/felixhultin/cross_lingual_relative_importance" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Relative word importance is a key metric for natural language processing. In this work, we compare human and model relative word importance to investigate if pretrained neural language models focus on the same words as humans cross-lingually. We perform an extensive study using several importance metrics (gradient-based saliency and attention-based) in monolingual and multilingual models, including eye-tracking corpora from four languages (German, Dutch, English, and Russian). We find that gradient-based saliency, first-layer attention, and attention flow correlate strongly with human eye-tracking data across all four languages. We further analyze the role of word length and word frequency in determining relative importance and find that it strongly correlates with length and frequency, however, the mechanisms behind these non-linear relations remain elusive. We obtain a cross-lingual approximation of the similarity between human and computational language processing and insights into the usability of several importance metrics.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICWSM</abbr></div> <div id="brandl2022evaluating" class="col-sm-8"> <div class="title">Evaluating Deep Taylor Decomposition for Reliability Assessment in the Wild</div> <div class="author"> <em>Brandl S.</em>, Hershcovich D., and Søgaard A.</div> <div class="periodical"> <em>In Proceedings of the International AAAI Conference on Web and Social Media</em> Jun 2022 </div> <div class="links"> <a href="https://twitter.com/StephanieBrandl/status/1534130582933880837?s=20&amp;t=rSziizmyafl5IxqjOgsOeA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/coastalcph/reliability-wild" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div> <div id="brandl-etal-2022-conservative" class="col-sm-8"> <div class="title">How Conservative are Language Models? Adapting to the Introduction of Gender-Neutral Pronouns</div> <div class="author"> <em>Brandl S.</em>, Cui R., and Søgaard A.</div> <div class="periodical"> <em>In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em> Jul 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.naacl-main.265" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1519352654899691520?s=20&amp;t=rSziizmyafl5IxqjOgsOeA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/gender-neutral-pronouns" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_naacl22.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Gender-neutral pronouns have recently been introduced in many languages to a) include non-binary people and b) as a generic singular. Recent results from psycholinguistics suggest that gender-neutral pronouns (in Swedish) are not associated with human processing difficulties. This, we show, is in sharp contrast with automated processing. We show that gender-neutral pronouns in Danish, English, and Swedish are associated with higher perplexity, more dispersed attention patterns, and worse downstream performance. We argue that such conservativity in language models may limit widespread adoption of gender-neutral pronouns and must therefore be resolved.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div> <div id="eberle2022transformer" class="col-sm-8"> <div class="title">Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?</div> <div class="author"> Eberle O.*, <em>Brandl S.*</em>, Pilot J., and Søgaard A.</div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> May 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.acl-long.296.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/oeberle/task_gaze_transformers" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_acl22.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Learned self-attention functions in state-of-the-art NLP models often correlate with human attention. We investigate whether self-attention in large-scale pre-trained language models is as predictive of human eye fixation patterns during task-reading as classical cognitive models of human attention. We compare attention functions across two task-specific reading datasets for sentiment analysis and relation extraction. We find the predictiveness of large-scale pre-trained self-attention for human attention depends on ‘what is in the tail’, e.g., the syntactic nature of rare contexts.Further, we observe that task-specific fine-tuning does not increase the correlation with human task-specific reading. Through an input reduction experiment we give complementary insights on the sparsity and fidelity trade-off, showing that lower-entropy attention vectors are more faithful.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div> <div id="hershcovich2022challenges" class="col-sm-8"> <div class="title">Challenges and Strategies in Cross-Cultural NLP</div> <div class="author"> Hershcovich D., Frank S., Lent H., Lhoneux M., Abdou M., <em>Brandl S.</em>, Bugliarello E., Cabello Piqueras L., Chalkidis I., Cui R., Fierro C., Margatina K., Rust P., and Søgaard A.</div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> May 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.acl-long.482.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/daniel_hers/status/1505829084210868224?s=20&amp;t=rSziizmyafl5IxqjOgsOeA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> </div> <div class="abstract hidden"> <p>Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.</p> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2021fourier" class="col-sm-8"> <div class="title">Fourier SPoC: A customised machine-learning analysis pipeline for auditory beat-based entrainment in the MEG\makebox[0pt][l]\phantom</div> <div class="author"> <em>Brandl Stephanie</em>, Haumann Niels Trusbak, Radloff Simjon, Dähne Sven, Bonetti Leonardo, Vuust Peter, Brattico Elvira, and Grube Manon</div> <div class="periodical"> <em>BioRxiv</em> 2021 </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2020motor" class="col-sm-8"> <div class="title">Motor Imagery Under Distraction—An Open Access BCI Dataset</div> <div class="author"> <em>Brandl Stephanie</em>, and Blankertz Benjamin</div> <div class="periodical"> <em>Frontiers in neuroscience</em> 2020 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2020balancing" class="col-sm-8"> <div class="title">Balancing the composition of word embeddings across heterogenous data sets</div> <div class="author"> <em>Brandl Stephanie</em>, Lassner David, and Alber Maximilian</div> <div class="periodical"> <em>arXiv preprint arXiv:2001.04693</em> 2020 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2020early" class="col-sm-8"> <div class="title">Early Corona Twitter Dataset</div> <div class="author"> <em>Brandl Stephanie</em>, and Lassner David</div> <div class="periodical"> <em>HAL preprint hal-02861167</em> 2020 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2020corona" class="col-sm-8"> <div class="title">Corona Twitter Dataset: 16 February 2020 - 03 March 2020</div> <div class="author"> <em>Brandl Stephanie</em>, and Lassner David</div> <div class="periodical"> 2020 </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2019times" class="col-sm-8"> <div class="title">Times Are Changing: Investigating the Pace of Language Change in Diachronic Word Embeddings</div> <div class="author"> <em>Brandl Stephanie</em>, and Lassner David</div> <div class="periodical"> <em>In Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change</em> 2019 </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="year">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2015bringing" class="col-sm-8"> <div class="title">Bringing BCI into everyday life: Motor imagery in a pseudo realistic environment</div> <div class="author"> <em>Brandl Stephanie</em>, Höhne Johannes, Müller Klaus-Robert, and Samek Wojciech</div> <div class="periodical"> <em>In 2015 7th International IEEE/EMBS Conference on Neural Engineering (NER)</em> 2015 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2015robust" class="col-sm-8"> <div class="title">Robust common spatial patterns based on Bhattacharyya distance and Gamma divergence</div> <div class="author"> <em>Brandl Stephanie</em>, Müller Klaus-Robert, and Samek Wojciech</div> <div class="periodical"> <em>In The 3rd International Winter Conference on Brain-Computer Interface</em> 2015 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="brandl2015distraction" class="col-sm-8"> <div class="title">BCI under distraction: Motor imagery in a pseudo realistic environment</div> <div class="author"> <em>Brandl Stephanie</em> </div> <div class="periodical"> 2015 </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Stephanie Brandl. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>