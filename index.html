<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Stephanie Brandl</title> <meta name="author" content="Stephanie Brandl"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://stephaniebrandl.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Stephanie</span> Brandl </h1> <p class="desc">PostDoc at the <a href="https://cpaicopenhagen.wordpress.com" target="_blank" rel="noopener noreferrer">Center for Philosophy of AI</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Karen Blixens Plads 8</p> <p>2300 Copenhagen</p> </div> </div> <div class="clearfix"> <p>I grew up in <a href="https://www.suedpfalz-tourismus.de/startseite.html?no_cache=1" target="_blank" rel="noopener noreferrer">southwestern Germany</a> at the border to France where the weather is good and people like to drink local wine out of <a href="https://de.wikipedia.org/wiki/Dubbeglas" target="_blank" rel="noopener noreferrer">funny-looking glasses</a> while chatting and eating <a href="https://en.wikipedia.org/wiki/Flammekueche" target="_blank" rel="noopener noreferrer">tarte flambée</a>.</p> <p>I moved to Berlin to study mathematics and social science. There the sky is usually grey, there is no wine and people are mostly grumpy. Nevertheless, the city grew on me and I stayed a little longer to complete my PhD in Machine Learning at <a href="https://www.ml.tu-berlin.de/menue/machine_learning/" target="_blank" rel="noopener noreferrer">TU Berlin</a>.</p> <p>In the midst of my PhD I realized that I find language even more exciting than the human brain which aligned well with <a href="https://coastalcph.github.io" target="_blank" rel="noopener noreferrer">CoAStaL</a> in Copenhagen where I joined as a PostDoc in 2021.</p> <p>I currently work on fairness and interpretability in NLP, also in combination with human reading (eye-tracking). I am most interested in making NLP equally accessible and transparent for everyone.</p> <p>I recently joined the <a href="https://cpaicopenhagen.wordpress.com" target="_blank" rel="noopener noreferrer">Center for Philosophy of AI</a> where I get the chance for enlightening discussions about AI and hope to contribute to the field with a new perspective.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive" style="max-height: 20vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Oct 1, 2024</th> <td> <img class="emoji" title=":thought_balloon:" alt=":thought_balloon:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4ad.png" height="20" width="20"> Excited to join <a href="https://cpaicopenhagen.wordpress.com/" target="_blank" rel="noopener noreferrer">CPAI</a> and looking forward to new perspectives and insights on Philosophy and AI! </td> </tr> <tr> <th scope="row">May 15, 2024</th> <td> <img class="emoji" title=":black_joker:" alt=":black_joker:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f0cf.png" height="20" width="20"> Our paper <a href="https://arxiv.org/pdf/2310.16607.pdf" target="_blank" rel="noopener noreferrer">On the Interplay between Fairness and Explainability</a> has been accepted to the <a href="https://trustnlpworkshop.github.io" target="_blank" rel="noopener noreferrer">TrustNLP Workshop</a> which is co-located with NAACL in Mexico <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">. </td> </tr> <tr> <th scope="row">Mar 25, 2024</th> <td> <img class="emoji" title=":eu:" alt=":eu:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1ea-1f1fa.png" height="20" width="20"> Our paper <a href="https://arxiv.org/abs/2403.13592" target="_blank" rel="noopener noreferrer">Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs</a>, together with <a href="https://iliaschalkidis.github.io" target="_blank" rel="noopener noreferrer">Ilias Chalkidis</a> has been accepted to NAACL 2024 <img class="emoji" title=":stars:" alt=":stars:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f320.png" height="20" width="20">, see you all in Mexico <img class="emoji" title=":taco:" alt=":taco:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f32e.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Mar 8, 2024</th> <td> <img class="emoji" title=":ribbon:" alt=":ribbon:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f380.png" height="20" width="20"> Our paper <a href="https://arxiv.org/abs/2402.19133" target="_blank" rel="noopener noreferrer">Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations</a> has been accepted to LREC-COLING 2024 <img class="emoji" title=":heart_eyes:" alt=":heart_eyes:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f60d.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Oct 9, 2023</th> <td> <img class="emoji" title=":ferris_wheel:" alt=":ferris_wheel:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3a1.png" height="20" width="20"> We got two papers accepted to EMNLP: <br> <a href="https://arxiv.org/pdf/2310.11906.pdf" target="_blank" rel="noopener noreferrer">Rather a Nurse than a Physician – Contrastive Explanations under Investigation</a> together with <a href="https://oeberle.github.io" target="_blank" rel="noopener noreferrer">Oliver Eberle</a>, <a href="https://iliaschalkidis.github.io" target="_blank" rel="noopener noreferrer">Ilias Chalkidis</a> &amp; <a href="https://lautel.github.io" target="_blank" rel="noopener noreferrer">Laura Cabello</a> and<br> <a href="https://arxiv.org/pdf/2310.17530.pdf" target="_blank" rel="noopener noreferrer">Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models</a> also with <a href="https://lautel.github.io" target="_blank" rel="noopener noreferrer">Laura Cabello</a>, <a href="https://e-bug.github.io" target="_blank" rel="noopener noreferrer">Emanuele Bugliarello</a> &amp; <a href="https://elliottd.github.io" target="_blank" rel="noopener noreferrer">Desmond Elliott</a><br> See you in Singapore <img class="emoji" title=":city_sunset:" alt=":city_sunset:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f306.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Trust</abbr></div> <div id="brandl-etal-2024-interplay" class="col-sm-8"> <div class="title">On the Interplay between Fairness and Explainability</div> <div class="author"> <em>Brandl S.</em>, Bugliarello E., and Chalkidis I.</div> <div class="periodical"> <em>In Proceedings of the 4th Workshop on Trustworthy Natural Language Processing (TrustNLP 2024)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.trustnlp-1.10.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1717886845118197922?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="/assets/pdf/poster_trust24.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In order to build reliable and trustworthy NLP applications, models need to be both fair across different demographics and explainable. Usually these two objectives, fairness and explainability, are optimized and/or examined independently of each other. Instead, we argue that forthcoming, trustworthy NLP systems should consider both. In this work, we perform a first study to understand how they influence each other: do fair(er) models rely on more plausible rationales? and vice versa. To this end, we conduct experiments on two English multi-class text classification datasets, BIOS and ECtHR, that provide information on gender and nationality, respectively, as well as human-annotated rationales. We fine-tune pre-trained language models with several methods for (i) bias mitigation, which aims to improve fairness; (ii) rationale extraction, which aims to produce plausible explanations. We find that bias mitigation algorithms do not always lead to fairer models. Moreover, we discover that empirical fairness and explainability are orthogonal.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div> <div id="chalkidis-brandl-2024-llama" class="col-sm-8"> <div class="title">Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs</div> <div class="author"> Chalkidis I.*, and <em>Brandl S.*</em> </div> <div class="periodical"> Jun 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.naacl-short.40.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1772213802391490804?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/coastalcph/eu-politics-llms" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_eullama.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model’s political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUandI questionnaire. Llama Chat shows considerable knowledge of national parties’ positions and is capable of reasoning in context. The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">LREC-COLING</abbr></div> <div id="brandl-etal-2024-evaluating" class="col-sm-8"> <div class="title">Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale Annotations</div> <div class="author"> <em>Brandl S.</em>, Eberle O., Ribeiro T., Søgaard A., and Hollenstein N.</div> <div class="periodical"> May 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.lrec-main.580.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1763491432956858481" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/rationales-eyetracking-xai" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_lrec24.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Rationales in the form of manually annotated input spans usually serve as ground truth when evaluating explainability methods in NLP. They are, however, time-consuming and often biased by the annotation process. In this paper, we debate whether human gaze, in the form of webcam-based eye-tracking recordings, poses a valid alternative when evaluating importance scores. We evaluate the additional information provided by gaze data, such as total reading times, gaze entropy, and decoding accuracy with respect to human rationale annotations. We compare WebQAmGaze, a multilingual dataset for information-seeking QA, with attention and explainability-based importance scores for 4 different multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily be applied to other tasks and languages. Our findings suggest that gaze data offers valuable linguistic insights that could be leveraged to infer task difficulty and further show a comparable ranking of explainability methods to that of human rationales.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div> <div id="eberle2023nurse" class="col-sm-8"> <div class="title">Rather a Nurse than a Physician – Contrastive Explanations under Investigation</div> <div class="author"> Eberle O.*, Chalkidis I.*, Cabello L., and <em>Brandl S.</em> </div> <div class="periodical"> <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em> Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.emnlp-main.427.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://x.com/StephanieBrandl/status/1715001280370757846?s=20" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/coastalcph/humans-contrastive-xai" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_contrastive.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Contrastive explanations, where one decision is explained in contrast to another, are supposed to be closer to how humans explain a decision than non-contrastive explanations, where the decision is not necessarily referenced to an alternative. This claim has never been empirically validated. We analyze four English text-classification datasets (SST2, DynaSent, BIOS and DBpedia-Animals). We fine-tune and extract explanations from three different models (RoBERTa, GTP-2, and T5), each in three different sizes and apply three post-hoc explainability methods (LRP, GradientxInput, GradNorm). We furthermore collect and release human rationale annotations for a subset of 100 samples from the BIOS dataset for contrastive and non-contrastive settings. A cross-comparison between model-based rationales and human annotations, both in contrastive and non-contrastive settings, yields a high agreement between the two settings for models as well as for humans. Moreover, model-based explanations computed in both settings align equally well with human rationales. Thus, we empirically find that humans do not necessarily explain in a contrastive manner.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div> <div id="brandl-etal-2022-conservative" class="col-sm-8"> <div class="title">How Conservative are Language Models? Adapting to the Introduction of Gender-Neutral Pronouns</div> <div class="author"> <em>Brandl S.</em>, Cui R., and Søgaard A.</div> <div class="periodical"> <em>In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em> Jul 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.naacl-main.265" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://twitter.com/StephanieBrandl/status/1519352654899691520?s=20&amp;t=rSziizmyafl5IxqjOgsOeA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">TL;DR</a> <a href="https://github.com/stephaniebrandl/gender-neutral-pronouns" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> <a href="/assets/pdf/poster_naacl22.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Gender-neutral pronouns have recently been introduced in many languages to a) include non-binary people and b) as a generic singular. Recent results from psycholinguistics suggest that gender-neutral pronouns (in Swedish) are not associated with human processing difficulties. This, we show, is in sharp contrast with automated processing. We show that gender-neutral pronouns in Danish, English, and Swedish are associated with higher perplexity, more dispersed attention patterns, and worse downstream performance. We argue that such conservativity in language models may limit widespread adoption of gender-neutral pronouns and must therefore be resolved.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%62%72%61%6E%64%6C@%64%69.%6B%75.%64%6B" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=eCDiVTMAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/stephaniebrandl" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://twitter.com/StephanieBrandl" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> The best way to reach me is via email brandl[at]di.ku.dk </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Stephanie Brandl. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>